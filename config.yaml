# Research Assistant Configuration File
# This file centralizes all configuration for LLM, embeddings, and document processing

# LLM Configuration
llm:
  model_name: "llama-3.1-8b-instant"  # Faster, uses fewer tokens (good for development)
  # Alternative: "llama-3.3-70b-versatile" (better quality, but slower and uses more tokens)
  temperature: 0.7
  max_tokens: 2048

# Embeddings Configuration
embeddings:
  model_name: "sentence-transformers/all-MiniLM-L6-v2"
  device: "cpu"  # Use 'cuda' if GPU available
  normalize: true

# Vector Store Configuration
vectorstore:
  chunk_size: 1000
  chunk_overlap: 200
  persist_directory: "./data/vectorstore"

# Web Search Configuration
web_search:
  provider: "tavily"  # Using Tavily - designed for AI agents
  max_results: 5
  # Tavily API (get free key at https://tavily.com)
  tavily_api_key: "${TAVILY_API_KEY}"
