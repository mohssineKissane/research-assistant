# Research Assistant â€” Project Description

A personal research assistant that answers questions from uploaded PDFs and the live web. Supports two modes: a lightweight conversational RAG pipeline and a full autonomous agent with tool selection.

ğŸŒ **Live Demo:** [research-assistantgit-mmgpmwqhp9bnhhpzy64yrh.streamlit.app](https://research-assistantgit-mmgpmwqhp9bnhhpzy64yrh.streamlit.app/)

---

## 1. Project Goal

Build a **Personal Research Assistant** to learn LangChain by implementing all its core concepts through a practical, working application:
- RAG (Retrieval-Augmented Generation) pipelines
- Conversational chains with memory
- Autonomous agents with tool selection (ReAct pattern)
- Streamlit UI with session management
- Cloud deployment

---

## 2. Two Modes

### ğŸ”¹ Simple Mode â€” Conversational RAG
A fast, predictable document Q&A chain.

- User uploads PDFs â†’ chunked, embedded, stored in ChromaDB
- Every question retrieves the top-k most relevant chunks
- LangChain `ConversationalRetrievalChain` reformulates follow-up questions using chat history
- Answers always include source citations (file + page)
- Best for: questions where the answer is in the documents

### ğŸ¤– Agent Mode â€” Autonomous Research (Default)
An autonomous ReAct agent that decides which tool to use.

**ReAct Loop:**
```
Thought â†’ Action (tool call) â†’ Observation â†’ Thought â†’ ... â†’ Final Answer
```

**Available tools:**
| Tool | When the agent uses it |
|------|------------------------|
| `search_documents` | Question is about uploaded PDFs |
| `search_web` | Need current info, news, or info not in docs |
| `summarize_content` | User asks for a summary |

- Agent can chain multiple tools in one query
- Remembers conversation history (follow-up questions understood)
- Best for: complex research, recent events, multi-source synthesis

---

## 3. Tech Stack

| Component | Technology |
|-----------|------------|
| **LLM** | Groq â€” `llama-3.3-70b-versatile` |
| **Embeddings** | HuggingFace `all-MiniLM-L6-v2` (local) |
| **Vector DB** | ChromaDB (local) |
| **Web Search** | Tavily API |
| **Framework** | LangChain (chains, agents, memory) |
| **UI** | Streamlit |
| **Doc Processing** | PyPDF |
| **Package Manager** | uv |
| **Deployment** | Streamlit Community Cloud |

---

## 4. Architecture

```
User (Streamlit UI)
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Simple Mode          Agent Mode         â”‚
â”‚  ConversationalQA     ReAct Agent        â”‚
â”‚  Chain                    â†“              â”‚
â”‚      â†“           â”Œâ”€â”€â”€â”€â”¬â”€â”€â”´â”€â”€â”¬â”€â”€â”€â”€â”       â”‚
â”‚      â†“           â†“    â†“     â†“    â†“       â”‚
â”‚      â†“        DocSearch Web  Summarize   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â†“              â†“      â†“      â†“
   ChromaDB      ChromaDB Tavily ChromaDB
       â†“
 LLM (Groq llama-3.3-70b-versatile)
       â†“
 ConversationMemory (BufferWindowMemory)
       â†“
 Response with citations â†’ User
```

---

## 5. Project Structure

```
research-assistant/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ agent/              # ResearchAgent (ReAct) + AgentConfig
â”‚   â”œâ”€â”€ tools/              # document_search, web_search, summarization
â”‚   â”œâ”€â”€ chains/             # conversational.py, retrieval_qa.py
â”‚   â”œâ”€â”€ processing/         # PDF loader, text splitter, embeddings pipeline
â”‚   â”œâ”€â”€ vectorstore/        # ChromaDB wrapper
â”‚   â”œâ”€â”€ memory/             # ConversationMemoryManager
â”‚   â””â”€â”€ utils/              # config, llm, prompts, formatters
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ streamlit_app.py    # Main entry point
â”‚   â”œâ”€â”€ components/         # chat_interface, sidebar, document_viewer
â”‚   â””â”€â”€ utils/              # state_manager, ui_helpers
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ temp_uploads/       # Uploaded PDFs (session)
â”‚   â””â”€â”€ vectorstore/        # ChromaDB index
â”œâ”€â”€ notebooks/              # Jupyter experiments per LangChain concept
â”œâ”€â”€ .streamlit/
â”‚   â””â”€â”€ config.toml         # Streamlit server + theme config
â”œâ”€â”€ config.yaml             # LLM, embeddings, vectorstore settings
â”œâ”€â”€ requirements.txt        # Production dependencies
â”œâ”€â”€ pyproject.toml          # Project metadata (uv)
â””â”€â”€ .env                    # API keys (local only, never committed)
```

---

## 6. Key Implementation Details

**Memory:** `ConversationBufferWindowMemory` keeps the last 5 exchanges. Uses `output_key="answer"` for Simple Mode and `output_key="output"` for Agent Mode (matching `AgentExecutor`'s output key).

**Agent prompts:** The `conversational-react-description` agent requires a custom prefix/suffix with `{chat_history}`, `{input}`, `{agent_scratchpad}`. The prefix explicitly instructs the agent to always use tools before answering.

**Token management:** Web search results are capped at 3 results, content at 400 chars, URLs at 100 chars to stay within Groq's TPM limits.

**Secrets:** On Streamlit Cloud, `st.secrets` values are injected into `os.environ` at startup so all `os.getenv()` calls work without any code changes.

---

## 7. Feature Checklist

**Completed:**
- [x] Upload and process multiple PDFs
- [x] Semantic search with source citations
- [x] Conversational Q&A with memory (Simple Mode)
- [x] Autonomous agent with tool selection (Agent Mode)
- [x] Live web search via Tavily
- [x] Streamlit chat UI with session management
- [x] Mode switching (Simple â†” Agent) in settings
- [x] Deployed to Streamlit Community Cloud

**Not in scope:**
- âŒ User authentication / multi-user
- âŒ PDF export of reports
- âŒ Non-PDF file formats (Word, Excel)
- âŒ Persistent storage on cloud (re-upload needed after restart)
- âŒ Mobile-optimised UI

---

## 8. Deployment

**Platform:** Streamlit Community Cloud (free tier)

**Live URL:** https://research-assistantgit-mmgpmwqhp9bnhhpzy64yrh.streamlit.app/

**Required secrets (set in App Settings â†’ Secrets):**
```toml
GROQ_API_KEY = "..."
TAVILY_API_KEY = "..."
```

**Note:** No persistent disk on Streamlit Cloud â€” uploaded PDFs and the ChromaDB vector store reset on each cold restart. Users must re-upload documents per session.
