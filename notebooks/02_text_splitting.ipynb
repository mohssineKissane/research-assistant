{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "header",
            "metadata": {},
            "source": [
                "# Text Splitting Test\n",
                "This notebook tests the DocumentSplitter class for chunking documents into optimal sizes for embeddings."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "setup",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Project root: c:\\Users\\kissa\\OneDrive\\Desktop\\research-assistant\n"
                    ]
                }
            ],
            "source": [
                "# Setup: Add parent directory to path\n",
                "import sys\n",
                "from pathlib import Path\n",
                "\n",
                "project_root = Path.cwd().parent\n",
                "if str(project_root) not in sys.path:\n",
                "    sys.path.insert(0, str(project_root))\n",
                "\n",
                "print(f\"Project root: {project_root}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "imports",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Import classes\n",
                "from src.processing.document_loader import DocumentLoader\n",
                "from src.processing.text_splitter import DocumentSplitter"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "load_pdf",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loaded 9 pages from PDF\n"
                    ]
                }
            ],
            "source": [
                "# Load the sample PDF (from previous notebook)\n",
                "pdf_path = project_root / \"data\" / \"samples\" / \"sample.pdf\"\n",
                "\n",
                "loader = DocumentLoader()\n",
                "docs = loader.load_pdf(str(pdf_path))\n",
                "print(f\"Loaded {len(docs)} pages from PDF\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "split_documents",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Split 9 pages into 18 chunks\n"
                    ]
                }
            ],
            "source": [
                "# Split documents into chunks\n",
                "splitter = DocumentSplitter(chunk_size=1000, chunk_overlap=200)\n",
                "chunks = splitter.split_documents(docs)\n",
                "print(f\"Split {len(docs)} pages into {len(chunks)} chunks\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "inspect_first_chunk",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "First chunk content:\n",
                        "A Brief Introduction to Artificial Intelligence\n",
                        "What is AI and how is it going to shape the future \n",
                        "By Dibbyo Saha, Undergraduate Student, Computer Science,\n",
                        "Ryerson University\n",
                        "What is Artificial Intelligence?\n",
                        "Imag e by Gerd Altmann from Pixabay\n",
                        "Generally\n",
                        "speaking,\n",
                        "Artificial\n",
                        "Intelligence\n",
                        "is\n",
                        "a\n",
                        "computing\n",
                        "concept\n",
                        "that\n",
                        "helps\n",
                        "a \n",
                        "machine\n",
                        "think\n",
                        "and\n",
                        "solve\n",
                        "complex\n",
                        "problems\n",
                        "as\n",
                        "we\n",
                        "humans\n",
                        "do\n",
                        "with\n",
                        "our\n",
                        "intelligence. \n",
                        "For\n",
                        "example,\n",
                        "we\n",
                        "perform\n",
                        "a\n",
                        "task,\n",
                        "make\n",
                        "mistakes\n",
                        "and\n",
                        "learn\n",
                        "from\n",
                        "our\n",
                        "mistakes\n",
                        "(At \n",
                        "least\n",
                        "the\n",
                        "wise\n",
                        "ones\n",
                        "of\n",
                        "us\n",
                        "do!).\n",
                        "Likewise,\n",
                        "an\n",
                        "AI\n",
                        "or\n",
                        "Artificial\n",
                        "Intelligence\n",
                        "is\n",
                        "supposed \n",
                        "to\n",
                        "work\n",
                        "on\n",
                        "a\n",
                        "problem,\n",
                        "make\n",
                        "some\n",
                        "mistakes\n",
                        "in\n",
                        "solving\n",
                        "the\n",
                        "problem\n",
                        "and\n",
                        "learn\n",
                        "from \n",
                        "the\n",
                        "problems\n",
                        "in\n",
                        "a\n",
                        "self-correcting\n",
                        "manner\n",
                        "as\n",
                        "a\n",
                        "part\n",
                        "of\n",
                        "its\n",
                        "self-improvement.\n",
                        "Or\n",
                        "in \n",
                        "other\n",
                        "words,\n",
                        "think\n",
                        "of\n",
                        "this\n",
                        "like\n",
                        "playing\n",
                        "a\n",
                        "game\n",
                        "of\n",
                        "chess.\n",
                        "Every\n",
                        "bad\n",
                        "move\n",
                        "you\n",
                        "make \n",
                        "reduces\n",
                        "your\n",
                        "chances\n",
                        "of\n",
                        "winning\n",
                        "the\n",
                        "game.\n",
                        "So,\n",
                        "every\n",
                        "time\n",
                        "you\n",
                        "lose\n",
                        "against\n",
                        "your \n",
                        "friend,\n",
                        "you\n",
                        "try\n",
                        "remembering\n",
                        "the\n",
                        "moves\n",
                        "you\n",
                        "made\n",
                        "which\n",
                        "you\n",
                        "shouldn’t\n",
                        "have\n",
                        "and \n",
                        "apply\n",
                        "that\n",
                        "knowledge\n",
                        "in\n",
                        "\n",
                        "First chunk metadata:\n",
                        "{'source': 'c:\\\\Users\\\\kissa\\\\OneDrive\\\\Desktop\\\\research-assistant\\\\data\\\\samples\\\\sample.pdf', 'page': 0, 'filename': 'sample.pdf', 'upload_date': datetime.datetime(2026, 2, 5, 23, 49, 35, 746614), 'chunk_id': 0}\n"
                    ]
                }
            ],
            "source": [
                "# Inspect the first chunk\n",
                "print(\"First chunk content:\")\n",
                "print(chunks[0].page_content)\n",
                "print(\"\\nFirst chunk metadata:\")\n",
                "print(chunks[0].metadata)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "id": "chunk_statistics",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Chunk Statistics:\n",
                        "  Total chunks: 18\n",
                        "  Average size: 786 characters\n",
                        "  Min size: 288 characters\n",
                        "  Max size: 999 characters\n",
                        "  Chunk size limit: 1000 characters\n",
                        "  Chunk overlap: 200 characters\n"
                    ]
                }
            ],
            "source": [
                "# Analyze chunk sizes\n",
                "chunk_lengths = [len(chunk.page_content) for chunk in chunks]\n",
                "\n",
                "print(\"Chunk Statistics:\")\n",
                "print(f\"  Total chunks: {len(chunks)}\")\n",
                "print(f\"  Average size: {sum(chunk_lengths) / len(chunk_lengths):.0f} characters\")\n",
                "print(f\"  Min size: {min(chunk_lengths)} characters\")\n",
                "print(f\"  Max size: {max(chunk_lengths)} characters\")\n",
                "print(f\"  Chunk size limit: 1000 characters\")\n",
                "print(f\"  Chunk overlap: 200 characters\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "id": "test_different_sizes",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Testing different chunk sizes:\n",
                        "\n",
                        "Chunk size  500:  41 chunks (avg: 455 chars)\n",
                        "Chunk size 1000:  18 chunks (avg: 786 chars)\n",
                        "Chunk size 1500:  12 chunks (avg: 1086 chars)\n",
                        "Chunk size 2000:  10 chunks (avg: 1264 chars)\n"
                    ]
                }
            ],
            "source": [
                "# Experiment: Try different chunk sizes\n",
                "chunk_sizes = [500, 1000, 1500, 2000]\n",
                "\n",
                "print(\"Testing different chunk sizes:\\n\")\n",
                "for size in chunk_sizes:\n",
                "    splitter = DocumentSplitter(chunk_size=size, chunk_overlap=200)\n",
                "    test_chunks = splitter.split_documents(docs)\n",
                "    avg_size = sum(len(c.page_content) for c in test_chunks) / len(test_chunks)\n",
                "    print(f\"Chunk size {size:4d}: {len(test_chunks):3d} chunks (avg: {avg_size:.0f} chars)\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "id": "inspect_overlap",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Checking overlap between first two chunks:\n",
                        "\n",
                        "End of chunk 1:\n",
                        "friend,\n",
                        "you\n",
                        "try\n",
                        "remembering\n",
                        "the\n",
                        "moves\n",
                        "you\n",
                        "made\n",
                        "which\n",
                        "you\n",
                        "shouldn’t\n",
                        "have\n",
                        "and \n",
                        "apply\n",
                        "that\n",
                        "knowledge\n",
                        "in\n",
                        "\n",
                        "Start of chunk 2:\n",
                        "bad\n",
                        "move\n",
                        "you\n",
                        "make \n",
                        "reduces\n",
                        "your\n",
                        "chances\n",
                        "of\n",
                        "winning\n",
                        "the\n",
                        "game.\n",
                        "So,\n",
                        "every\n",
                        "time\n",
                        "you\n",
                        "lose\n",
                        "against\n",
                        "your \n",
                        "f\n",
                        "\n",
                        "(Notice the overlap preserves context)\n"
                    ]
                }
            ],
            "source": [
                "# Verify overlap between consecutive chunks\n",
                "if len(chunks) >= 2:\n",
                "    print(\"Checking overlap between first two chunks:\\n\")\n",
                "    chunk1_end = chunks[0].page_content[-100:]\n",
                "    chunk2_start = chunks[1].page_content[:100]\n",
                "    \n",
                "    print(\"End of chunk 1:\")\n",
                "    print(chunk1_end)\n",
                "    print(\"\\nStart of chunk 2:\")\n",
                "    print(chunk2_start)\n",
                "    print(\"\\n(Notice the overlap preserves context)\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.14"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
