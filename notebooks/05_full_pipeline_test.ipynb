{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Full Pipeline Test\n",
                "\n",
                "**Goal**: Test the complete document processing pipeline with real PDF\n",
                "\n",
                "This notebook tests the full integration:\n",
                "1. Load PDF documents\n",
                "2. Split into chunks\n",
                "3. Generate embeddings\n",
                "4. Store in ChromaDB\n",
                "5. Perform similarity search"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "from pathlib import Path\n",
                "\n",
                "# Add project root to path\n",
                "project_root = Path().absolute().parent\n",
                "sys.path.insert(0, str(project_root))\n",
                "\n",
                "from src.processing.document_loader import DocumentLoader\n",
                "from src.processing.text_splitter import DocumentSplitter\n",
                "from src.processing.embeddings import EmbeddingsGenerator\n",
                "from src.vectorstore.chroma_store import ChromaVectorStore"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Test 1: Initialize All Components\n",
                "\n",
                "Create instances of all pipeline components"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Initializing pipeline components...\n",
                        "\n",
                        "‚úì DocumentLoader initialized\n",
                        "‚úì DocumentSplitter initialized\n",
                        "  Chunk size: 1000\n",
                        "  Chunk overlap: 200\n",
                        "‚úì EmbeddingsGenerator initialized\n",
                        "‚úì ChromaVectorStore initialized\n",
                        "  Persist directory: ./data/vectorstore_pipeline_test\n"
                    ]
                }
            ],
            "source": [
                "print(\"Initializing pipeline components...\\n\")\n",
                "\n",
                "# Document loader\n",
                "loader = DocumentLoader()\n",
                "print(\"‚úì DocumentLoader initialized\")\n",
                "\n",
                "# Text splitter\n",
                "splitter = DocumentSplitter(\n",
                "    chunk_size=1000,\n",
                "    chunk_overlap=200\n",
                ")\n",
                "print(\"‚úì DocumentSplitter initialized\")\n",
                "print(f\"  Chunk size: {splitter.chunk_size}\")\n",
                "print(f\"  Chunk overlap: {splitter.chunk_overlap}\")\n",
                "\n",
                "# Embeddings generator\n",
                "embedder = EmbeddingsGenerator()\n",
                "print(\"‚úì EmbeddingsGenerator initialized\")\n",
                "\n",
                "# Vector store manager\n",
                "vectorstore_manager = ChromaVectorStore(\n",
                "    embeddings=embedder,\n",
                "    persist_directory=\"./data/vectorstore_pipeline_test\"\n",
                ")\n",
                "print(\"‚úì ChromaVectorStore initialized\")\n",
                "print(f\"  Persist directory: {vectorstore_manager.persist_directory}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Test 2: Load PDF Document\n",
                "\n",
                "Load the sample PDF from data/samples/sample.pdf"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loading PDF: ../data/samples/sample.pdf\n",
                        "\n",
                        "‚úì Loaded 9 pages from PDF\n",
                        "\n",
                        "First page preview:\n",
                        "  Content length: 1134 characters\n",
                        "  Metadata: {'source': '../data/samples/sample.pdf', 'page': 0, 'filename': 'sample.pdf', 'upload_date': '2026-02-07T18:27:02.529060'}\n",
                        "  First 200 chars: A Brief Introduction to Artificial Intelligence\n",
                        "What is AI and how is it going to shape the future \n",
                        "By Dibbyo Saha, Undergraduate Student, Computer Science,\n",
                        "Ryerson University\n",
                        "What is Artificial Intel...\n"
                    ]
                }
            ],
            "source": [
                "pdf_path = \"../data/samples/sample.pdf\"\n",
                "print(f\"Loading PDF: {pdf_path}\\n\")\n",
                "\n",
                "docs = loader.load_pdf(pdf_path)\n",
                "\n",
                "print(f\"‚úì Loaded {len(docs)} pages from PDF\\n\")\n",
                "\n",
                "# Show first document info\n",
                "if docs:\n",
                "    print(\"First page preview:\")\n",
                "    print(f\"  Content length: {len(docs[0].page_content)} characters\")\n",
                "    print(f\"  Metadata: {docs[0].metadata}\")\n",
                "    print(f\"  First 200 chars: {docs[0].page_content[:200]}...\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Test 3: Split Documents into Chunks\n",
                "\n",
                "Split the loaded documents into smaller chunks for embedding"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Splitting documents into chunks...\n",
                        "\n",
                        "‚úì Created 18 chunks\n",
                        "\n",
                        "Chunk statistics:\n",
                        "  Average length: 786 characters\n",
                        "  Min length: 288 characters\n",
                        "  Max length: 999 characters\n",
                        "\n",
                        "First chunk preview:\n",
                        "  Length: 999 characters\n",
                        "  Content: A Brief Introduction to Artificial Intelligence\n",
                        "What is AI and how is it going to shape the future \n",
                        "By Dibbyo Saha, Undergraduate Student, Computer Science,\n",
                        "Ryerson University\n",
                        "What is Artificial Intel...\n",
                        "  Metadata: {'source': '../data/samples/sample.pdf', 'page': 0, 'filename': 'sample.pdf', 'upload_date': '2026-02-07T18:27:02.529060', 'chunk_id': 0}\n"
                    ]
                }
            ],
            "source": [
                "print(\"Splitting documents into chunks...\\n\")\n",
                "\n",
                "chunks = splitter.split_documents(docs)\n",
                "\n",
                "print(f\"‚úì Created {len(chunks)} chunks\\n\")\n",
                "\n",
                "# Show chunk statistics\n",
                "chunk_lengths = [len(chunk.page_content) for chunk in chunks]\n",
                "print(\"Chunk statistics:\")\n",
                "print(f\"  Average length: {sum(chunk_lengths) / len(chunk_lengths):.0f} characters\")\n",
                "print(f\"  Min length: {min(chunk_lengths)} characters\")\n",
                "print(f\"  Max length: {max(chunk_lengths)} characters\")\n",
                "\n",
                "# Show first chunk\n",
                "print(f\"\\nFirst chunk preview:\")\n",
                "print(f\"  Length: {len(chunks[0].page_content)} characters\")\n",
                "print(f\"  Content: {chunks[0].page_content[:200]}...\")\n",
                "print(f\"  Metadata: {chunks[0].metadata}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Test 4: Create Vector Store\n",
                "\n",
                "Generate embeddings and store chunks in ChromaDB"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Creating vector store with embeddings...\n",
                        "\n",
                        "This may take a moment...\n",
                        "\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
                        "Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úì Vector store created successfully!\n",
                        "‚úì Stored 18 chunks with embeddings\n",
                        "‚úì Collection name: pipeline_test\n"
                    ]
                }
            ],
            "source": [
                "print(\"Creating vector store with embeddings...\\n\")\n",
                "print(\"This may take a moment...\\n\")\n",
                "\n",
                "vectorstore = vectorstore_manager.create_from_documents(\n",
                "    documents=chunks,\n",
                "    collection_name=\"pipeline_test\"\n",
                ")\n",
                "\n",
                "print(\"‚úì Vector store created successfully!\")\n",
                "print(f\"‚úì Stored {len(chunks)} chunks with embeddings\")\n",
                "print(f\"‚úì Collection name: pipeline_test\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Test 5: Similarity Search\n",
                "\n",
                "Test semantic search on the stored documents"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Failed to send telemetry event CollectionQueryEvent: capture() takes 1 positional argument but 3 were given\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Query: 'What is Artificial Intelligence?'\n",
                        "\n",
                        "‚úì Found 3 most relevant chunks:\n",
                        "\n",
                        "--- Result 1 ---\n",
                        "Content: A Brief Introduction to Artificial Intelligence\n",
                        "What is AI and how is it going to shape the future \n",
                        "By Dibbyo Saha, Undergraduate Student, Computer Science,\n",
                        "Ryerson University\n",
                        "What is Artificial Intel...\n",
                        "Metadata: {'chunk_id': 0, 'filename': 'sample.pdf', 'page': 0, 'source': '../data/samples/sample.pdf', 'upload_date': '2026-02-07T18:27:02.529060'}\n",
                        "\n",
                        "--- Result 2 ---\n",
                        "Content: Intelligence\n",
                        "as\n",
                        "a \n",
                        "process\n",
                        "that\n",
                        "is\n",
                        "going\n",
                        "to\n",
                        "help\n",
                        "machines\n",
                        "achieve\n",
                        "a\n",
                        "humanlike\n",
                        "mental\n",
                        "behaviour.\n",
                        "AI\n",
                        "is \n",
                        "a\n",
                        "vast\n",
                        "and\n",
                        "growing\n",
                        "field\n",
                        "which\n",
                        "also\n",
                        "includes\n",
                        "a\n",
                        "lot\n",
                        "more\n",
                        "subfields\n",
                        "like\n",
                        "machine \n",
                        "learning\n",
                        "and\n",
                        "deep...\n",
                        "Metadata: {'chunk_id': 6, 'filename': 'sample.pdf', 'page': 2, 'source': '../data/samples/sample.pdf', 'upload_date': '2026-02-07T18:27:02.529060'}\n",
                        "\n",
                        "--- Result 3 ---\n",
                        "Content: complicated\n",
                        "and\n",
                        "intuitive\n",
                        "sense\n",
                        "of\n",
                        "thinking\n",
                        "and\n",
                        "problem-solving\n",
                        "abilities\n",
                        "of\n",
                        "the \n",
                        "human mind.\n",
                        "A Brief History of AI\n",
                        "The\n",
                        "concept\n",
                        "of\n",
                        "Artificial\n",
                        "Intelligence\n",
                        "is\n",
                        "not\n",
                        "as\n",
                        "modern\n",
                        "as\n",
                        "we\n",
                        "think\n",
                        "it\n",
                        "is.\n",
                        "This\n",
                        "trac...\n",
                        "Metadata: {'chunk_id': 5, 'filename': 'sample.pdf', 'page': 2, 'source': '../data/samples/sample.pdf', 'upload_date': '2026-02-07T18:27:02.529060'}\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "# Test query - adjust based on your PDF content\n",
                "query = \"What is Artificial Intelligence?\"\n",
                "\n",
                "print(f\"Query: '{query}'\\n\")\n",
                "\n",
                "results = vectorstore_manager.similarity_search(query, k=3)\n",
                "\n",
                "print(f\"‚úì Found {len(results)} most relevant chunks:\\n\")\n",
                "\n",
                "for i, result in enumerate(results, 1):\n",
                "    print(f\"--- Result {i} ---\")\n",
                "    print(f\"Content: {result.page_content[:200]}...\")\n",
                "    print(f\"Metadata: {result.metadata}\")\n",
                "    print()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Test 6: Multiple Queries\n",
                "\n",
                "Test different types of queries"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Testing multiple queries:\n",
                        "\n",
                        "======================================================================\n",
                        "\n",
                        "Query: 'What is the difference between AI and traditional robotics?'\n",
                        "----------------------------------------------------------------------\n",
                        "  1. improves\n",
                        "by\n",
                        "a\n",
                        "noteworthy\n",
                        "extent.\n",
                        "AI\n",
                        "is\n",
                        "programmed\n",
                        "to\n",
                        "do\n",
                        "something\n",
                        "similar\n",
                        "to \n",
                        "that!\n",
                        "Artificial Intel...\n",
                        "     Source: page 1\n",
                        "  2. complicated\n",
                        "and\n",
                        "intuitive\n",
                        "sense\n",
                        "of\n",
                        "thinking\n",
                        "and\n",
                        "problem-solving\n",
                        "abilities\n",
                        "of\n",
                        "the \n",
                        "human mind.\n",
                        "A Brie...\n",
                        "     Source: page 2\n",
                        "\n",
                        "Query: 'What are the subfields of AI mentioned in the document?'\n",
                        "----------------------------------------------------------------------\n",
                        "  1. A Brief Introduction to Artificial Intelligence\n",
                        "What is AI and how is it going to shape the future \n",
                        "...\n",
                        "     Source: page 0\n",
                        "  2. Sour ce:h ttp://da tasciencecen tral.com\n",
                        "Deep\n",
                        "Learning,\n",
                        "on\n",
                        "the\n",
                        "other\n",
                        "hand\n",
                        "is\n",
                        "the\n",
                        "concept\n",
                        "of\n",
                        "computer...\n",
                        "     Source: page 4\n",
                        "\n",
                        "Query: 'How will AI impact jobs in the future?'\n",
                        "----------------------------------------------------------------------\n",
                        "  1. great\n",
                        "tool\n",
                        "in\n",
                        "the\n",
                        "future\n",
                        "of\n",
                        "education.\n",
                        "AI\n",
                        "can\n",
                        "be\n",
                        "used\n",
                        "to\n",
                        "analyze\n",
                        "data\n",
                        "from\n",
                        "an \n",
                        "individual‚Äôs\n",
                        "personal...\n",
                        "     Source: page 6\n",
                        "  2. Intelligence\n",
                        "is\n",
                        "also\n",
                        "viewed\n",
                        "as\n",
                        "a\n",
                        "great\n",
                        "tool\n",
                        "for\n",
                        "better\n",
                        "cybersecurity.\n",
                        "Many\n",
                        "banks\n",
                        "are \n",
                        "using\n",
                        "AI\n",
                        "as\n",
                        "a\n",
                        "...\n",
                        "     Source: page 5\n",
                        "\n",
                        "Query: 'What are some current applications of AI?'\n",
                        "----------------------------------------------------------------------\n",
                        "  1. Sour ce:h ttp://da tasciencecen tral.com\n",
                        "Deep\n",
                        "Learning,\n",
                        "on\n",
                        "the\n",
                        "other\n",
                        "hand\n",
                        "is\n",
                        "the\n",
                        "concept\n",
                        "of\n",
                        "computer...\n",
                        "     Source: page 4\n",
                        "  2. complicated\n",
                        "and\n",
                        "intuitive\n",
                        "sense\n",
                        "of\n",
                        "thinking\n",
                        "and\n",
                        "problem-solving\n",
                        "abilities\n",
                        "of\n",
                        "the \n",
                        "human mind.\n",
                        "A Brie...\n",
                        "     Source: page 2\n"
                    ]
                }
            ],
            "source": [
                "# Adjust these queries based on your PDF content\n",
                "test_queries = [\n",
                "    \"What is the difference between AI and traditional robotics?\",\n",
                "    \"What are the subfields of AI mentioned in the document?\",\n",
                "    \"How will AI impact jobs in the future?\",\n",
                "    \"What are some current applications of AI?\"\n",
                "]\n",
                "\n",
                "print(\"Testing multiple queries:\\n\")\n",
                "print(\"=\" * 70)\n",
                "\n",
                "for query in test_queries:\n",
                "    print(f\"\\nQuery: '{query}'\")\n",
                "    print(\"-\" * 70)\n",
                "    \n",
                "    results = vectorstore_manager.similarity_search(query, k=2)\n",
                "    \n",
                "    for i, result in enumerate(results, 1):\n",
                "        print(f\"  {i}. {result.page_content[:100]}...\")\n",
                "        print(f\"     Source: page {result.metadata.get('page', 'unknown')}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Test 7: Search with Scores\n",
                "\n",
                "Get relevance scores to understand search quality"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Query: 'Explain Machine Learning and Deep Learning'\n",
                        "\n",
                        "‚úì Top 5 results with relevance scores:\n",
                        "\n",
                        "--- Result 1 (Score: 0.7966) ---\n",
                        "Page: 2\n",
                        "Content: Intelligence\n",
                        "as\n",
                        "a \n",
                        "process\n",
                        "that\n",
                        "is\n",
                        "going\n",
                        "to\n",
                        "help\n",
                        "machines\n",
                        "achieve\n",
                        "a\n",
                        "humanlike\n",
                        "mental\n",
                        "behaviour.\n",
                        "AI\n",
                        "is \n",
                        "a\n",
                        "vast\n",
                        "and\n",
                        "growing\n",
                        "field\n",
                        "which\n",
                        "also\n",
                        "includes\n",
                        "a\n",
                        "...\n",
                        "\n",
                        "--- Result 2 (Score: 0.8995) ---\n",
                        "Page: 4\n",
                        "Content: Sour ce:h ttp://da tasciencecen tral.com\n",
                        "Deep\n",
                        "Learning,\n",
                        "on\n",
                        "the\n",
                        "other\n",
                        "hand\n",
                        "is\n",
                        "the\n",
                        "concept\n",
                        "of\n",
                        "computers\n",
                        "simulating\n",
                        "the \n",
                        "process\n",
                        "a\n",
                        "human\n",
                        "brain\n",
                        "takes\n",
                        "to\n",
                        "a...\n",
                        "\n",
                        "--- Result 3 (Score: 0.9833) ---\n",
                        "Page: 3\n",
                        "Content: which\n",
                        "is\n",
                        "not\n",
                        "apparently\n",
                        "comprehendible\n",
                        "by\n",
                        "the\n",
                        "human\n",
                        "eyes.\n",
                        "The \n",
                        "machine\n",
                        "looks\n",
                        "for\n",
                        "patterns\n",
                        "and\n",
                        "draws\n",
                        "conclusions\n",
                        "on\n",
                        "its\n",
                        "own\n",
                        "from\n",
                        "the\n",
                        "patterns\n",
                        "of \n",
                        "the\n",
                        "d...\n",
                        "\n",
                        "--- Result 4 (Score: 1.0602) ---\n",
                        "Page: 3\n",
                        "Content: is\n",
                        "being\n",
                        "trained\n",
                        "by\n",
                        "giving\n",
                        "it\n",
                        "access\n",
                        "to\n",
                        "a\n",
                        "huge\n",
                        "amount\n",
                        "of\n",
                        "data\n",
                        "and\n",
                        "training\n",
                        "the \n",
                        "machine\n",
                        "to\n",
                        "analyze\n",
                        "it.\n",
                        "For\n",
                        "instance,\n",
                        "the\n",
                        "machine\n",
                        "is\n",
                        "given\n",
                        "a\n",
                        "number\n",
                        "of\n",
                        "...\n",
                        "\n",
                        "--- Result 5 (Score: 1.0617) ---\n",
                        "Page: 0\n",
                        "Content: A Brief Introduction to Artificial Intelligence\n",
                        "What is AI and how is it going to shape the future \n",
                        "By Dibbyo Saha, Undergraduate Student, Computer Sc...\n",
                        "\n",
                        "Note: Lower scores = higher similarity in ChromaDB\n"
                    ]
                }
            ],
            "source": [
                "query = \"Explain Machine Learning and Deep Learning\"\n",
                "\n",
                "print(f\"Query: '{query}'\\n\")\n",
                "\n",
                "results_with_scores = vectorstore_manager.similarity_search_with_score(query, k=5)\n",
                "\n",
                "print(f\"‚úì Top {len(results_with_scores)} results with relevance scores:\\n\")\n",
                "\n",
                "for i, (doc, score) in enumerate(results_with_scores, 1):\n",
                "    print(f\"--- Result {i} (Score: {score:.4f}) ---\")\n",
                "    print(f\"Page: {doc.metadata.get('page', 'unknown')}\")\n",
                "    print(f\"Content: {doc.page_content[:150]}...\")\n",
                "    print()\n",
                "\n",
                "print(\"Note: Lower scores = higher similarity in ChromaDB\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Test 8: Using the Pipeline Class\n",
                "\n",
                "Test the DocumentProcessingPipeline class for streamlined processing"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úì Pipeline initialized with config:\n",
                        "  Chunk size: 1000\n",
                        "  Chunk overlap: 200\n",
                        "  Embedding model: sentence-transformers/all-MiniLM-L6-v2\n",
                        "  Vectorstore path: ./data/vectorstore_pipeline_class_test\n"
                    ]
                }
            ],
            "source": [
                "from src.processing.document_processing_pipeline import DocumentProcessingPipeline, PipelineConfig\n",
                "\n",
                "# Create configuration\n",
                "config = PipelineConfig(\n",
                "    chunk_size=1000,\n",
                "    chunk_overlap=200,\n",
                "    embedding_model=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
                "    vectorstore_path=\"./data/vectorstore_pipeline_class_test\"\n",
                ")\n",
                "\n",
                "# Initialize pipeline\n",
                "pipeline = DocumentProcessingPipeline(config)\n",
                "\n",
                "print(\"‚úì Pipeline initialized with config:\")\n",
                "print(f\"  Chunk size: {config.chunk_size}\")\n",
                "print(f\"  Chunk overlap: {config.chunk_overlap}\")\n",
                "print(f\"  Embedding model: {config.embedding_model}\")\n",
                "print(f\"  Vectorstore path: {config.vectorstore_path}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Processing PDF with pipeline...\n",
                        "\n",
                        "üì• Loading 1 PDFs...\n",
                        "‚úÖ Loaded 9 pages\n",
                        "‚úÇÔ∏è  Splitting documents into chunks...\n",
                        "‚úÖ Created 18 chunks\n",
                        "üî¢ Generating embeddings and storing in vector database...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
                        "Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úÖ Processing complete! Vector store ready for search.\n",
                        "\n",
                        "‚úì Pipeline processing complete!\n"
                    ]
                }
            ],
            "source": [
                "# Process PDF using pipeline\n",
                "pdf_paths = [\"../data/samples/sample.pdf\"]\n",
                "\n",
                "print(\"\\nProcessing PDF with pipeline...\\n\")\n",
                "vectorstore = pipeline.process_pdfs(pdf_paths)\n",
                "\n",
                "print(\"\\n‚úì Pipeline processing complete!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Searching with query: 'What concerns exist about AI and automation?'\n",
                        "\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Failed to send telemetry event CollectionQueryEvent: capture() takes 1 positional argument but 3 were given\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úì Found 3 results:\n",
                        "\n",
                        "1. great\n",
                        "tool\n",
                        "in\n",
                        "the\n",
                        "future\n",
                        "of\n",
                        "education.\n",
                        "AI\n",
                        "can\n",
                        "be\n",
                        "used\n",
                        "to\n",
                        "analyze\n",
                        "data\n",
                        "from\n",
                        "an \n",
                        "individual‚Äôs\n",
                        "personal\n",
                        "and\n",
                        "intellectual\n",
                        "needs,\n",
                        "capabilities,\n",
                        "choices\n",
                        "and...\n",
                        "   Page: 6\n",
                        "\n",
                        "2. Intelligence\n",
                        "is\n",
                        "also\n",
                        "viewed\n",
                        "as\n",
                        "a\n",
                        "great\n",
                        "tool\n",
                        "for\n",
                        "better\n",
                        "cybersecurity.\n",
                        "Many\n",
                        "banks\n",
                        "are \n",
                        "using\n",
                        "AI\n",
                        "as\n",
                        "a\n",
                        "means\n",
                        "to\n",
                        "identify\n",
                        "unauthorized\n",
                        "credit\n",
                        "cards\n",
                        "uses.\n",
                        "...\n",
                        "   Page: 5\n",
                        "\n",
                        "3. fears\n",
                        "regarding\n",
                        "AI \n",
                        "includes\n",
                        "the\n",
                        "scenario\n",
                        "whereas\n",
                        "machines\n",
                        "become\n",
                        "smarter\n",
                        "and\n",
                        "smarter\n",
                        "they\n",
                        "going\n",
                        "to \n",
                        "end\n",
                        "up\n",
                        "being\n",
                        "as\n",
                        "opinionated\n",
                        "and\n",
                        "biased\n",
                        "like\n",
                        "some\n",
                        "...\n",
                        "   Page: 5\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "# Search using pipeline\n",
                "query = \"What concerns exist about AI and automation?\"\n",
                "\n",
                "print(f\"\\nSearching with query: '{query}'\\n\")\n",
                "\n",
                "results = pipeline.search(query, k=3)\n",
                "\n",
                "print(f\"‚úì Found {len(results)} results:\\n\")\n",
                "\n",
                "for i, result in enumerate(results, 1):\n",
                "    print(f\"{i}. {result.page_content[:150]}...\")\n",
                "    print(f\"   Page: {result.metadata.get('page', 'unknown')}\\n\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Summary\n",
                "\n",
                "### What We Tested:\n",
                "1. ‚úÖ Initialized all pipeline components\n",
                "2. ‚úÖ Loaded PDF document\n",
                "3. ‚úÖ Split documents into chunks\n",
                "4. ‚úÖ Created vector store with embeddings\n",
                "5. ‚úÖ Performed similarity search\n",
                "6. ‚úÖ Tested multiple queries\n",
                "7. ‚úÖ Got relevance scores\n",
                "8. ‚úÖ Used DocumentProcessingPipeline class\n",
                "\n",
                "### Full Pipeline Verified:\n",
                "```\n",
                "PDF ‚Üí DocumentLoader ‚Üí Documents\n",
                "  ‚Üì\n",
                "DocumentSplitter ‚Üí Chunks\n",
                "  ‚Üì\n",
                "EmbeddingsGenerator ‚Üí Vectors\n",
                "  ‚Üì\n",
                "ChromaVectorStore ‚Üí Searchable Database\n",
                "  ‚Üì\n",
                "Similarity Search ‚Üí Relevant Results\n",
                "```\n",
                "\n",
                "### Key Findings:\n",
                "- **Complete Integration**: All components work together seamlessly\n",
                "- **Real PDF Processing**: Successfully processed actual PDF file\n",
                "- **Semantic Search**: Finds relevant content based on meaning\n",
                "- **Pipeline Class**: Simplifies the entire workflow\n",
                "- **Persistence**: Data saved to disk for reuse\n",
                "\n",
                "### Next Steps:\n",
                "1. Integrate with RAG (Retrieval-Augmented Generation) for Q&A\n",
                "2. Add support for multiple document types\n",
                "3. Implement advanced filtering and metadata search\n",
                "4. Build a user interface for document upload and search"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.14"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
