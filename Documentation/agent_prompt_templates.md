# How Agent Prompt Templates Work

## The Big Picture

When you call `initialize_agent()`, LangChain builds **one big string** that gets sent to the LLM on every step of the ReAct loop. You control the top and bottom of this string — that's prefix and suffix.

```
┌─────────────────────────────────────────────────┐
│  PREFIX   ← your get_conversational_agent_prefix()  │
│                                                   │
│  You are a research assistant that ALWAYS uses    │
│  tools... CRITICAL RULES: 1. ALWAYS use...        │
│                                                   │
├─────────────────────────────────────────────────┤
│  TOOL DESCRIPTIONS  ← auto-generated by LangChain │
│                                                   │
│  search_documents: Use this tool to search...     │
│  search_web: Use this tool to search the internet │
│  summarize_content: Use this tool to create...    │
│                                                   │
├─────────────────────────────────────────────────┤
│  SUFFIX   ← your get_conversational_agent_suffix() │
│                                                   │
│  Begin! You MUST use a tool...                    │
│  Previous conversation: {chat_history}            │
│  New input: {input}                               │
│  {agent_scratchpad}                               │
└─────────────────────────────────────────────────┘
```

**You never see the tool descriptions section** — LangChain generates it automatically from each tool's `name` and `description` fields. Your prefix/suffix sandwich around it.

---

## The Three Placeholders in the Suffix

These are filled at runtime by LangChain, not by you:

```python
return """Begin! You MUST use a tool before providing a Final Answer.

Previous conversation history:
{chat_history}       ← Memory injects the last 5 Q&A pairs here

New input: {input}   ← The user's actual question goes here

{agent_scratchpad}   ← THIS IS THE MAGIC: the whole Thought/Action/Observation
                        history from THIS turn gets appended here as the
                        agent loops
"""
```

**`{agent_scratchpad}` explained** — this starts empty, then grows with each loop iteration:

```
# Iteration 1 — scratchpad is empty, LLM reasons first time:
{agent_scratchpad} = ""

LLM outputs →  Thought: I need to search docs first
               Action: search_documents
               Action Input: "transformers"

# Iteration 2 — LangChain appends the result to scratchpad:
{agent_scratchpad} = """
Thought: I need to search docs first
Action: search_documents
Action Input: transformers
Observation: Found in paper: Transformers use attention...

Thought:"""     ← LLM continues from here
```

The LLM sees its own previous reasoning steps each time, which is how it knows what it has already done.

---

## How It's Wired In

In `src/agent/research_agent.py`:

```python
# 1. Build the prompt pieces
conversational_agent_kwargs = {
    'prefix': AgentConfig.get_conversational_agent_prefix(),
    'suffix': AgentConfig.get_conversational_agent_suffix(),
}

# 2. Pass to LangChain — it assembles the full prompt internally
initialize_agent(
    tools=self.tools,
    llm=self.llm,
    agent=AgentType.CONVERSATIONAL_REACT_DESCRIPTION,
    agent_kwargs=conversational_agent_kwargs,  # ← your prefix/suffix injected here
    memory=self.memory.get_memory(),           # ← fills {chat_history}
    ...
)
```

---

## Why Prefix vs Suffix

| | Prefix | Suffix |
|--|--------|--------|
| **Position** | Top of prompt | Bottom of prompt |
| **Purpose** | Set the agent's identity and rules | Contains the dynamic placeholders |
| **Changes per turn?** | No — static instructions | Yes — `{chat_history}`, `{input}`, `{agent_scratchpad}` change every call |
| **Key content** | Role, CRITICAL RULES, tool strategy | The actual conversation and reasoning space |

**The prefix is where you control behaviour** — notice the `CRITICAL RULES` block in `get_conversational_agent_prefix()`. That's the prompt engineering that forces the agent to always call a tool before answering, try `search_web` for recent events, etc. Without those rules, the LLM might just answer from its training data and skip the tools entirely.
